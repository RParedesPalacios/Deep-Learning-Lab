{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "num_classes = 10\n",
    "epochs = 150\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#### LOAD AND TRANSFORM\n",
    "# The output of torchvision datasets are PILImage images of range [0, 1].\n",
    "# https://pytorch.org/docs/stable/torchvision/transforms.html\n",
    "train_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomAffine(degrees=20, translate=(0.2, 0.2), scale=(1.0, 1.2)),\n",
    "    torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10('./data', train=True, download=True, transform=train_transforms)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "test_transforms = torchvision.transforms.Compose([\n",
    "                        torchvision.transforms.ToTensor(),\n",
    "                        torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "                  ])\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10('./data', train=False, download=True, transform=test_transforms)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 50000 samples - Max value: 2.7537312507629395 - Min value: -2.429065704345703\n"
     ]
    }
   ],
   "source": [
    "x_batch, y_batch = iter(train_loader).next()\n",
    "print(\"Training set: {} samples - Max value: {} - Min value: {}\".format(len(train_loader.dataset), \n",
    "                                                                        x_batch.max(), x_batch.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: 10000 samples - Max value: 2.7537312507629395 - Min value: -2.429065704345703\n"
     ]
    }
   ],
   "source": [
    "x_batch, y_batch = iter(test_loader).next()\n",
    "print(\"Test set: {} samples - Max value: {} - Min value: {}\".format(len(test_loader.dataset), \n",
    "                                                                        x_batch.max(), x_batch.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example batch shape: torch.Size([100, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "print(\"Example batch shape: {}\".format(x_batch.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNoise(nn.Module):\n",
    "    \"\"\"Gaussian noise regularizer.\n",
    "\n",
    "    Args:\n",
    "        sigma (float, optional): relative standard deviation used to generate the\n",
    "            noise. Relative means that it will be multiplied by the magnitude of\n",
    "            the value your are adding the noise to. This means that sigma can be\n",
    "            the same regardless of the scale of the vector.\n",
    "        is_relative_detach (bool, optional): whether to detach the variable before\n",
    "            computing the scale of the noise. If `False` then the scale of the noise\n",
    "            won't be seen as a constant but something to optimize: this will bias the\n",
    "            network to generate vectors with smaller values.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sigma=0.1, is_relative_detach=True):\n",
    "        super().__init__()\n",
    "        self.sigma = sigma\n",
    "        self.is_relative_detach = is_relative_detach\n",
    "        self.noise = torch.tensor(0).to(device).float()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training and self.sigma != 0:\n",
    "            scale = self.sigma * x.detach() if self.is_relative_detach else self.sigma * x\n",
    "            sampled_noise = self.noise.repeat(*x.size()).normal_() * scale\n",
    "            x = x + sampled_noise\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (block1): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): GaussianNoise()\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): GaussianNoise()\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (block2): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): GaussianNoise()\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): GaussianNoise()\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (block3): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): GaussianNoise()\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): GaussianNoise()\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (block4): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): GaussianNoise()\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): GaussianNoise()\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (block5): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): GaussianNoise()\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): GaussianNoise()\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (features): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (reluFeatures): ReLU()\n",
      "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.block1 = self._CBGN(3, 32)\n",
    "        self.block2 = self._CBGN(32, 64)\n",
    "        self.block3 = self._CBGN(64, 128)\n",
    "        self.block4 = self._CBGN(128, 256)\n",
    "        self.block5 = self._CBGN(256, 512)\n",
    "        # Flatten at forward!\n",
    "        self.features = nn.Linear(512, 512)\n",
    "        self.reluFeatures = nn.ReLU()\n",
    "        self.classifier = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.block1(x)               # 32x32 -> 16x16 @ 32\n",
    "        out = self.block2(out)             # 16x16 -> 8x8 @ 64\n",
    "        out = self.block3(out)             # 8x8 -> 4x4 @ 128\n",
    "        out = self.block4(out)             # 4x4 -> 2x2 @ 256\n",
    "        out = self.block5(out)             # 2x2 -> 1x1 @ 512\n",
    "        out = out.view(out.size(0), -1)    # Flatten\n",
    "        out = self.reluFeatures(self.features(out))  # 512 -> 512\n",
    "        out = self.classifier(out)         # 512 -> num_classes (10)\n",
    "        return out\n",
    "\n",
    "    # DEF A BLOCK Conv + BN + GN + MaxPool\n",
    "    def _CBGN(self, in_channels, filters):\n",
    "        layers = []\n",
    "        \n",
    "        layers += [nn.Conv2d(in_channels, filters, kernel_size=(3,3), padding=1)]\n",
    "        layers += [nn.BatchNorm2d(filters)]\n",
    "        layers += [GaussianNoise(0.3)]\n",
    "        layers += [nn.ReLU()]\n",
    "        \n",
    "        layers += [nn.Conv2d(filters, filters, kernel_size=(3,3), padding=1)]\n",
    "        layers += [nn.BatchNorm2d(filters)]\n",
    "        layers += [GaussianNoise(0.3)]\n",
    "        layers += [nn.ReLU()]\n",
    "        \n",
    "        layers += [nn.MaxPool2d(kernel_size=(2,2))]\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "net = Net().to(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, weight_decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = 0.1     if epoch < 50\n",
    "# lr = 0.01    if 30 <= epoch < 100\n",
    "# lr = 0.001   if epoch >= 100\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50, 100], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Start Training ----\n",
      "[Epoch 1] LR: 0.100 - Train Loss: 0.01692 - Test Loss: 0.01488 - Train Accuracy: 36.74% - Test Accuracy: 45.85%\n",
      "[Epoch 2] LR: 0.100 - Train Loss: 0.01335 - Test Loss: 0.01198 - Train Accuracy: 51.36% - Test Accuracy: 56.35%\n",
      "[Epoch 3] LR: 0.100 - Train Loss: 0.01175 - Test Loss: 0.01051 - Train Accuracy: 57.78% - Test Accuracy: 61.83%\n",
      "[Epoch 4] LR: 0.100 - Train Loss: 0.01074 - Test Loss: 0.00964 - Train Accuracy: 61.79% - Test Accuracy: 65.12%\n",
      "[Epoch 5] LR: 0.100 - Train Loss: 0.00990 - Test Loss: 0.00897 - Train Accuracy: 64.92% - Test Accuracy: 67.01%\n",
      "[Epoch 6] LR: 0.100 - Train Loss: 0.00932 - Test Loss: 0.00770 - Train Accuracy: 67.29% - Test Accuracy: 72.20%\n",
      "[Epoch 7] LR: 0.100 - Train Loss: 0.00885 - Test Loss: 0.00782 - Train Accuracy: 68.77% - Test Accuracy: 72.05%\n",
      "[Epoch 8] LR: 0.100 - Train Loss: 0.00846 - Test Loss: 0.00731 - Train Accuracy: 70.26% - Test Accuracy: 73.73%\n",
      "[Epoch 9] LR: 0.100 - Train Loss: 0.00813 - Test Loss: 0.00722 - Train Accuracy: 71.58% - Test Accuracy: 74.40%\n",
      "[Epoch 10] LR: 0.100 - Train Loss: 0.00784 - Test Loss: 0.00647 - Train Accuracy: 72.54% - Test Accuracy: 77.23%\n",
      "[Epoch 11] LR: 0.100 - Train Loss: 0.00764 - Test Loss: 0.00666 - Train Accuracy: 73.17% - Test Accuracy: 76.44%\n",
      "[Epoch 12] LR: 0.100 - Train Loss: 0.00739 - Test Loss: 0.00648 - Train Accuracy: 74.18% - Test Accuracy: 76.17%\n",
      "[Epoch 13] LR: 0.100 - Train Loss: 0.00720 - Test Loss: 0.00619 - Train Accuracy: 74.70% - Test Accuracy: 78.38%\n",
      "[Epoch 14] LR: 0.100 - Train Loss: 0.00701 - Test Loss: 0.00623 - Train Accuracy: 75.44% - Test Accuracy: 78.00%\n",
      "[Epoch 15] LR: 0.100 - Train Loss: 0.00687 - Test Loss: 0.00652 - Train Accuracy: 76.07% - Test Accuracy: 76.99%\n",
      "[Epoch 16] LR: 0.100 - Train Loss: 0.00673 - Test Loss: 0.00550 - Train Accuracy: 76.44% - Test Accuracy: 80.42%\n",
      "[Epoch 17] LR: 0.100 - Train Loss: 0.00658 - Test Loss: 0.00560 - Train Accuracy: 77.03% - Test Accuracy: 80.48%\n",
      "[Epoch 18] LR: 0.100 - Train Loss: 0.00645 - Test Loss: 0.00526 - Train Accuracy: 77.45% - Test Accuracy: 81.52%\n",
      "[Epoch 19] LR: 0.100 - Train Loss: 0.00636 - Test Loss: 0.00553 - Train Accuracy: 77.66% - Test Accuracy: 80.71%\n",
      "[Epoch 20] LR: 0.100 - Train Loss: 0.00621 - Test Loss: 0.00528 - Train Accuracy: 78.42% - Test Accuracy: 81.48%\n",
      "[Epoch 21] LR: 0.100 - Train Loss: 0.00609 - Test Loss: 0.00514 - Train Accuracy: 78.69% - Test Accuracy: 82.08%\n",
      "[Epoch 22] LR: 0.100 - Train Loss: 0.00599 - Test Loss: 0.00524 - Train Accuracy: 78.94% - Test Accuracy: 81.43%\n",
      "[Epoch 23] LR: 0.100 - Train Loss: 0.00589 - Test Loss: 0.00512 - Train Accuracy: 79.54% - Test Accuracy: 82.01%\n",
      "[Epoch 24] LR: 0.100 - Train Loss: 0.00587 - Test Loss: 0.00468 - Train Accuracy: 79.46% - Test Accuracy: 84.13%\n",
      "[Epoch 25] LR: 0.100 - Train Loss: 0.00577 - Test Loss: 0.00481 - Train Accuracy: 79.96% - Test Accuracy: 83.60%\n",
      "[Epoch 26] LR: 0.100 - Train Loss: 0.00564 - Test Loss: 0.00511 - Train Accuracy: 80.28% - Test Accuracy: 82.03%\n",
      "[Epoch 27] LR: 0.100 - Train Loss: 0.00562 - Test Loss: 0.00479 - Train Accuracy: 80.33% - Test Accuracy: 83.70%\n",
      "[Epoch 28] LR: 0.100 - Train Loss: 0.00553 - Test Loss: 0.00489 - Train Accuracy: 80.79% - Test Accuracy: 83.04%\n",
      "[Epoch 29] LR: 0.100 - Train Loss: 0.00545 - Test Loss: 0.00470 - Train Accuracy: 80.70% - Test Accuracy: 83.76%\n",
      "[Epoch 30] LR: 0.100 - Train Loss: 0.00541 - Test Loss: 0.00465 - Train Accuracy: 81.00% - Test Accuracy: 84.10%\n",
      "[Epoch 31] LR: 0.100 - Train Loss: 0.00534 - Test Loss: 0.00462 - Train Accuracy: 81.22% - Test Accuracy: 84.14%\n",
      "[Epoch 32] LR: 0.100 - Train Loss: 0.00528 - Test Loss: 0.00446 - Train Accuracy: 81.39% - Test Accuracy: 84.58%\n",
      "[Epoch 33] LR: 0.100 - Train Loss: 0.00518 - Test Loss: 0.00456 - Train Accuracy: 81.88% - Test Accuracy: 84.03%\n",
      "[Epoch 34] LR: 0.100 - Train Loss: 0.00519 - Test Loss: 0.00431 - Train Accuracy: 81.88% - Test Accuracy: 85.39%\n",
      "[Epoch 35] LR: 0.100 - Train Loss: 0.00507 - Test Loss: 0.00458 - Train Accuracy: 82.12% - Test Accuracy: 84.24%\n",
      "[Epoch 36] LR: 0.100 - Train Loss: 0.00504 - Test Loss: 0.00430 - Train Accuracy: 82.03% - Test Accuracy: 85.32%\n",
      "[Epoch 37] LR: 0.100 - Train Loss: 0.00499 - Test Loss: 0.00471 - Train Accuracy: 82.36% - Test Accuracy: 83.65%\n",
      "[Epoch 38] LR: 0.100 - Train Loss: 0.00493 - Test Loss: 0.00437 - Train Accuracy: 82.59% - Test Accuracy: 84.83%\n",
      "[Epoch 39] LR: 0.100 - Train Loss: 0.00489 - Test Loss: 0.00448 - Train Accuracy: 82.98% - Test Accuracy: 84.55%\n",
      "[Epoch 40] LR: 0.100 - Train Loss: 0.00486 - Test Loss: 0.00431 - Train Accuracy: 83.00% - Test Accuracy: 85.25%\n",
      "[Epoch 41] LR: 0.100 - Train Loss: 0.00477 - Test Loss: 0.00447 - Train Accuracy: 83.25% - Test Accuracy: 84.53%\n",
      "[Epoch 42] LR: 0.100 - Train Loss: 0.00480 - Test Loss: 0.00415 - Train Accuracy: 83.26% - Test Accuracy: 85.37%\n",
      "[Epoch 43] LR: 0.100 - Train Loss: 0.00472 - Test Loss: 0.00435 - Train Accuracy: 83.41% - Test Accuracy: 85.02%\n",
      "[Epoch 44] LR: 0.100 - Train Loss: 0.00463 - Test Loss: 0.00419 - Train Accuracy: 83.80% - Test Accuracy: 85.34%\n",
      "[Epoch 45] LR: 0.100 - Train Loss: 0.00459 - Test Loss: 0.00431 - Train Accuracy: 83.92% - Test Accuracy: 84.98%\n",
      "[Epoch 46] LR: 0.100 - Train Loss: 0.00452 - Test Loss: 0.00401 - Train Accuracy: 83.98% - Test Accuracy: 86.25%\n",
      "[Epoch 47] LR: 0.100 - Train Loss: 0.00455 - Test Loss: 0.00414 - Train Accuracy: 83.98% - Test Accuracy: 85.52%\n",
      "[Epoch 48] LR: 0.100 - Train Loss: 0.00451 - Test Loss: 0.00438 - Train Accuracy: 84.21% - Test Accuracy: 84.60%\n",
      "[Epoch 49] LR: 0.100 - Train Loss: 0.00449 - Test Loss: 0.00403 - Train Accuracy: 84.20% - Test Accuracy: 86.36%\n",
      "[Epoch 50] LR: 0.100 - Train Loss: 0.00444 - Test Loss: 0.00410 - Train Accuracy: 84.34% - Test Accuracy: 86.04%\n",
      "[Epoch 51] LR: 0.100 - Train Loss: 0.00432 - Test Loss: 0.00382 - Train Accuracy: 84.88% - Test Accuracy: 86.54%\n",
      "[Epoch 52] LR: 0.010 - Train Loss: 0.00400 - Test Loss: 0.00359 - Train Accuracy: 85.96% - Test Accuracy: 87.69%\n",
      "[Epoch 53] LR: 0.010 - Train Loss: 0.00377 - Test Loss: 0.00358 - Train Accuracy: 86.73% - Test Accuracy: 87.82%\n",
      "[Epoch 54] LR: 0.010 - Train Loss: 0.00375 - Test Loss: 0.00361 - Train Accuracy: 86.78% - Test Accuracy: 87.71%\n",
      "[Epoch 55] LR: 0.010 - Train Loss: 0.00373 - Test Loss: 0.00357 - Train Accuracy: 86.80% - Test Accuracy: 87.84%\n",
      "[Epoch 56] LR: 0.010 - Train Loss: 0.00369 - Test Loss: 0.00355 - Train Accuracy: 86.92% - Test Accuracy: 87.92%\n",
      "[Epoch 57] LR: 0.010 - Train Loss: 0.00373 - Test Loss: 0.00352 - Train Accuracy: 86.73% - Test Accuracy: 87.99%\n",
      "[Epoch 58] LR: 0.010 - Train Loss: 0.00369 - Test Loss: 0.00354 - Train Accuracy: 86.88% - Test Accuracy: 88.07%\n",
      "[Epoch 59] LR: 0.010 - Train Loss: 0.00366 - Test Loss: 0.00354 - Train Accuracy: 86.98% - Test Accuracy: 87.88%\n",
      "[Epoch 60] LR: 0.010 - Train Loss: 0.00364 - Test Loss: 0.00353 - Train Accuracy: 87.18% - Test Accuracy: 88.04%\n",
      "[Epoch 61] LR: 0.010 - Train Loss: 0.00360 - Test Loss: 0.00358 - Train Accuracy: 87.27% - Test Accuracy: 87.91%\n",
      "[Epoch 62] LR: 0.010 - Train Loss: 0.00362 - Test Loss: 0.00352 - Train Accuracy: 87.23% - Test Accuracy: 88.00%\n",
      "[Epoch 63] LR: 0.010 - Train Loss: 0.00356 - Test Loss: 0.00359 - Train Accuracy: 87.38% - Test Accuracy: 87.86%\n",
      "[Epoch 64] LR: 0.010 - Train Loss: 0.00356 - Test Loss: 0.00355 - Train Accuracy: 87.37% - Test Accuracy: 88.00%\n",
      "[Epoch 65] LR: 0.010 - Train Loss: 0.00354 - Test Loss: 0.00356 - Train Accuracy: 87.59% - Test Accuracy: 87.85%\n",
      "[Epoch 66] LR: 0.010 - Train Loss: 0.00355 - Test Loss: 0.00361 - Train Accuracy: 87.42% - Test Accuracy: 87.77%\n",
      "[Epoch 67] LR: 0.010 - Train Loss: 0.00357 - Test Loss: 0.00358 - Train Accuracy: 87.32% - Test Accuracy: 87.68%\n",
      "[Epoch 68] LR: 0.010 - Train Loss: 0.00357 - Test Loss: 0.00359 - Train Accuracy: 87.23% - Test Accuracy: 87.71%\n",
      "[Epoch 69] LR: 0.010 - Train Loss: 0.00357 - Test Loss: 0.00353 - Train Accuracy: 87.47% - Test Accuracy: 87.82%\n",
      "[Epoch 70] LR: 0.010 - Train Loss: 0.00354 - Test Loss: 0.00355 - Train Accuracy: 87.68% - Test Accuracy: 87.86%\n",
      "[Epoch 71] LR: 0.010 - Train Loss: 0.00353 - Test Loss: 0.00355 - Train Accuracy: 87.37% - Test Accuracy: 88.00%\n",
      "[Epoch 72] LR: 0.010 - Train Loss: 0.00352 - Test Loss: 0.00352 - Train Accuracy: 87.48% - Test Accuracy: 88.13%\n",
      "[Epoch 73] LR: 0.010 - Train Loss: 0.00351 - Test Loss: 0.00351 - Train Accuracy: 87.71% - Test Accuracy: 88.13%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 74] LR: 0.010 - Train Loss: 0.00348 - Test Loss: 0.00353 - Train Accuracy: 87.69% - Test Accuracy: 88.04%\n",
      "[Epoch 75] LR: 0.010 - Train Loss: 0.00349 - Test Loss: 0.00348 - Train Accuracy: 87.65% - Test Accuracy: 88.12%\n",
      "[Epoch 76] LR: 0.010 - Train Loss: 0.00346 - Test Loss: 0.00352 - Train Accuracy: 87.72% - Test Accuracy: 87.90%\n",
      "[Epoch 77] LR: 0.010 - Train Loss: 0.00347 - Test Loss: 0.00352 - Train Accuracy: 87.75% - Test Accuracy: 88.01%\n",
      "[Epoch 78] LR: 0.010 - Train Loss: 0.00344 - Test Loss: 0.00356 - Train Accuracy: 87.87% - Test Accuracy: 87.68%\n",
      "[Epoch 79] LR: 0.010 - Train Loss: 0.00343 - Test Loss: 0.00353 - Train Accuracy: 87.81% - Test Accuracy: 87.95%\n",
      "[Epoch 80] LR: 0.010 - Train Loss: 0.00343 - Test Loss: 0.00354 - Train Accuracy: 87.80% - Test Accuracy: 87.89%\n",
      "[Epoch 81] LR: 0.010 - Train Loss: 0.00344 - Test Loss: 0.00352 - Train Accuracy: 87.80% - Test Accuracy: 88.07%\n",
      "[Epoch 82] LR: 0.010 - Train Loss: 0.00342 - Test Loss: 0.00351 - Train Accuracy: 87.90% - Test Accuracy: 88.02%\n",
      "[Epoch 83] LR: 0.010 - Train Loss: 0.00342 - Test Loss: 0.00350 - Train Accuracy: 87.80% - Test Accuracy: 88.05%\n",
      "[Epoch 84] LR: 0.010 - Train Loss: 0.00344 - Test Loss: 0.00353 - Train Accuracy: 87.74% - Test Accuracy: 88.00%\n",
      "[Epoch 85] LR: 0.010 - Train Loss: 0.00344 - Test Loss: 0.00346 - Train Accuracy: 87.63% - Test Accuracy: 88.09%\n",
      "[Epoch 86] LR: 0.010 - Train Loss: 0.00338 - Test Loss: 0.00348 - Train Accuracy: 87.99% - Test Accuracy: 88.23%\n",
      "[Epoch 87] LR: 0.010 - Train Loss: 0.00338 - Test Loss: 0.00348 - Train Accuracy: 88.03% - Test Accuracy: 88.17%\n",
      "[Epoch 88] LR: 0.010 - Train Loss: 0.00340 - Test Loss: 0.00353 - Train Accuracy: 87.88% - Test Accuracy: 88.02%\n",
      "[Epoch 89] LR: 0.010 - Train Loss: 0.00339 - Test Loss: 0.00347 - Train Accuracy: 88.00% - Test Accuracy: 88.22%\n",
      "[Epoch 90] LR: 0.010 - Train Loss: 0.00336 - Test Loss: 0.00351 - Train Accuracy: 88.07% - Test Accuracy: 88.05%\n",
      "[Epoch 91] LR: 0.010 - Train Loss: 0.00341 - Test Loss: 0.00349 - Train Accuracy: 87.88% - Test Accuracy: 88.17%\n",
      "[Epoch 92] LR: 0.010 - Train Loss: 0.00337 - Test Loss: 0.00350 - Train Accuracy: 87.95% - Test Accuracy: 88.06%\n",
      "[Epoch 93] LR: 0.010 - Train Loss: 0.00332 - Test Loss: 0.00349 - Train Accuracy: 88.09% - Test Accuracy: 88.04%\n",
      "[Epoch 94] LR: 0.010 - Train Loss: 0.00336 - Test Loss: 0.00353 - Train Accuracy: 88.03% - Test Accuracy: 87.86%\n",
      "[Epoch 95] LR: 0.010 - Train Loss: 0.00332 - Test Loss: 0.00350 - Train Accuracy: 88.37% - Test Accuracy: 88.06%\n",
      "[Epoch 96] LR: 0.010 - Train Loss: 0.00335 - Test Loss: 0.00344 - Train Accuracy: 88.17% - Test Accuracy: 88.07%\n",
      "[Epoch 97] LR: 0.010 - Train Loss: 0.00338 - Test Loss: 0.00351 - Train Accuracy: 88.07% - Test Accuracy: 87.88%\n",
      "[Epoch 98] LR: 0.010 - Train Loss: 0.00334 - Test Loss: 0.00348 - Train Accuracy: 88.08% - Test Accuracy: 88.00%\n",
      "[Epoch 99] LR: 0.010 - Train Loss: 0.00331 - Test Loss: 0.00350 - Train Accuracy: 88.16% - Test Accuracy: 88.08%\n",
      "[Epoch 100] LR: 0.010 - Train Loss: 0.00332 - Test Loss: 0.00350 - Train Accuracy: 88.35% - Test Accuracy: 87.99%\n",
      "[Epoch 101] LR: 0.010 - Train Loss: 0.00330 - Test Loss: 0.00344 - Train Accuracy: 88.19% - Test Accuracy: 88.15%\n",
      "[Epoch 102] LR: 0.001 - Train Loss: 0.00327 - Test Loss: 0.00346 - Train Accuracy: 88.31% - Test Accuracy: 88.09%\n",
      "[Epoch 103] LR: 0.001 - Train Loss: 0.00327 - Test Loss: 0.00347 - Train Accuracy: 88.35% - Test Accuracy: 88.15%\n",
      "[Epoch 104] LR: 0.001 - Train Loss: 0.00329 - Test Loss: 0.00344 - Train Accuracy: 88.32% - Test Accuracy: 88.21%\n",
      "[Epoch 105] LR: 0.001 - Train Loss: 0.00318 - Test Loss: 0.00346 - Train Accuracy: 88.79% - Test Accuracy: 88.14%\n",
      "[Epoch 106] LR: 0.001 - Train Loss: 0.00320 - Test Loss: 0.00347 - Train Accuracy: 88.54% - Test Accuracy: 88.17%\n",
      "[Epoch 107] LR: 0.001 - Train Loss: 0.00322 - Test Loss: 0.00346 - Train Accuracy: 88.57% - Test Accuracy: 88.14%\n",
      "[Epoch 108] LR: 0.001 - Train Loss: 0.00329 - Test Loss: 0.00346 - Train Accuracy: 88.31% - Test Accuracy: 88.18%\n",
      "[Epoch 109] LR: 0.001 - Train Loss: 0.00324 - Test Loss: 0.00345 - Train Accuracy: 88.50% - Test Accuracy: 88.22%\n",
      "[Epoch 110] LR: 0.001 - Train Loss: 0.00324 - Test Loss: 0.00345 - Train Accuracy: 88.48% - Test Accuracy: 88.21%\n",
      "[Epoch 111] LR: 0.001 - Train Loss: 0.00326 - Test Loss: 0.00344 - Train Accuracy: 88.44% - Test Accuracy: 88.29%\n",
      "[Epoch 112] LR: 0.001 - Train Loss: 0.00324 - Test Loss: 0.00346 - Train Accuracy: 88.51% - Test Accuracy: 88.14%\n",
      "[Epoch 113] LR: 0.001 - Train Loss: 0.00321 - Test Loss: 0.00348 - Train Accuracy: 88.59% - Test Accuracy: 88.16%\n",
      "[Epoch 114] LR: 0.001 - Train Loss: 0.00323 - Test Loss: 0.00344 - Train Accuracy: 88.58% - Test Accuracy: 88.30%\n",
      "[Epoch 115] LR: 0.001 - Train Loss: 0.00324 - Test Loss: 0.00346 - Train Accuracy: 88.56% - Test Accuracy: 88.23%\n",
      "[Epoch 116] LR: 0.001 - Train Loss: 0.00325 - Test Loss: 0.00345 - Train Accuracy: 88.42% - Test Accuracy: 88.19%\n",
      "[Epoch 117] LR: 0.001 - Train Loss: 0.00323 - Test Loss: 0.00346 - Train Accuracy: 88.55% - Test Accuracy: 88.25%\n",
      "[Epoch 118] LR: 0.001 - Train Loss: 0.00320 - Test Loss: 0.00348 - Train Accuracy: 88.50% - Test Accuracy: 88.11%\n",
      "[Epoch 119] LR: 0.001 - Train Loss: 0.00324 - Test Loss: 0.00348 - Train Accuracy: 88.56% - Test Accuracy: 88.10%\n",
      "[Epoch 120] LR: 0.001 - Train Loss: 0.00323 - Test Loss: 0.00346 - Train Accuracy: 88.48% - Test Accuracy: 88.21%\n",
      "[Epoch 121] LR: 0.001 - Train Loss: 0.00323 - Test Loss: 0.00347 - Train Accuracy: 88.66% - Test Accuracy: 88.13%\n",
      "[Epoch 122] LR: 0.001 - Train Loss: 0.00324 - Test Loss: 0.00345 - Train Accuracy: 88.51% - Test Accuracy: 88.25%\n",
      "[Epoch 123] LR: 0.001 - Train Loss: 0.00321 - Test Loss: 0.00348 - Train Accuracy: 88.68% - Test Accuracy: 88.14%\n",
      "[Epoch 124] LR: 0.001 - Train Loss: 0.00321 - Test Loss: 0.00347 - Train Accuracy: 88.50% - Test Accuracy: 88.11%\n",
      "[Epoch 125] LR: 0.001 - Train Loss: 0.00324 - Test Loss: 0.00346 - Train Accuracy: 88.42% - Test Accuracy: 88.18%\n",
      "[Epoch 126] LR: 0.001 - Train Loss: 0.00324 - Test Loss: 0.00347 - Train Accuracy: 88.55% - Test Accuracy: 88.16%\n",
      "[Epoch 127] LR: 0.001 - Train Loss: 0.00322 - Test Loss: 0.00347 - Train Accuracy: 88.56% - Test Accuracy: 88.14%\n",
      "[Epoch 128] LR: 0.001 - Train Loss: 0.00319 - Test Loss: 0.00348 - Train Accuracy: 88.68% - Test Accuracy: 88.11%\n",
      "[Epoch 129] LR: 0.001 - Train Loss: 0.00315 - Test Loss: 0.00345 - Train Accuracy: 88.76% - Test Accuracy: 88.25%\n",
      "[Epoch 130] LR: 0.001 - Train Loss: 0.00319 - Test Loss: 0.00348 - Train Accuracy: 88.66% - Test Accuracy: 88.20%\n",
      "[Epoch 131] LR: 0.001 - Train Loss: 0.00321 - Test Loss: 0.00347 - Train Accuracy: 88.53% - Test Accuracy: 88.21%\n",
      "[Epoch 132] LR: 0.001 - Train Loss: 0.00320 - Test Loss: 0.00346 - Train Accuracy: 88.54% - Test Accuracy: 88.13%\n",
      "[Epoch 133] LR: 0.001 - Train Loss: 0.00323 - Test Loss: 0.00346 - Train Accuracy: 88.44% - Test Accuracy: 88.15%\n",
      "[Epoch 134] LR: 0.001 - Train Loss: 0.00321 - Test Loss: 0.00347 - Train Accuracy: 88.65% - Test Accuracy: 88.14%\n",
      "[Epoch 135] LR: 0.001 - Train Loss: 0.00316 - Test Loss: 0.00348 - Train Accuracy: 88.70% - Test Accuracy: 88.11%\n",
      "[Epoch 136] LR: 0.001 - Train Loss: 0.00321 - Test Loss: 0.00346 - Train Accuracy: 88.63% - Test Accuracy: 88.16%\n",
      "[Epoch 137] LR: 0.001 - Train Loss: 0.00322 - Test Loss: 0.00348 - Train Accuracy: 88.71% - Test Accuracy: 88.15%\n",
      "[Epoch 138] LR: 0.001 - Train Loss: 0.00320 - Test Loss: 0.00345 - Train Accuracy: 88.68% - Test Accuracy: 88.23%\n",
      "[Epoch 139] LR: 0.001 - Train Loss: 0.00323 - Test Loss: 0.00345 - Train Accuracy: 88.56% - Test Accuracy: 88.19%\n",
      "[Epoch 140] LR: 0.001 - Train Loss: 0.00321 - Test Loss: 0.00346 - Train Accuracy: 88.57% - Test Accuracy: 88.14%\n",
      "[Epoch 141] LR: 0.001 - Train Loss: 0.00321 - Test Loss: 0.00345 - Train Accuracy: 88.53% - Test Accuracy: 88.11%\n",
      "[Epoch 142] LR: 0.001 - Train Loss: 0.00320 - Test Loss: 0.00345 - Train Accuracy: 88.56% - Test Accuracy: 88.17%\n",
      "[Epoch 143] LR: 0.001 - Train Loss: 0.00322 - Test Loss: 0.00344 - Train Accuracy: 88.47% - Test Accuracy: 88.15%\n",
      "[Epoch 144] LR: 0.001 - Train Loss: 0.00320 - Test Loss: 0.00345 - Train Accuracy: 88.76% - Test Accuracy: 88.17%\n",
      "[Epoch 145] LR: 0.001 - Train Loss: 0.00318 - Test Loss: 0.00346 - Train Accuracy: 88.71% - Test Accuracy: 88.13%\n",
      "[Epoch 146] LR: 0.001 - Train Loss: 0.00322 - Test Loss: 0.00345 - Train Accuracy: 88.45% - Test Accuracy: 88.13%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 147] LR: 0.001 - Train Loss: 0.00319 - Test Loss: 0.00348 - Train Accuracy: 88.65% - Test Accuracy: 88.17%\n",
      "[Epoch 148] LR: 0.001 - Train Loss: 0.00318 - Test Loss: 0.00347 - Train Accuracy: 88.73% - Test Accuracy: 88.20%\n",
      "[Epoch 149] LR: 0.001 - Train Loss: 0.00321 - Test Loss: 0.00345 - Train Accuracy: 88.51% - Test Accuracy: 88.30%\n",
      "[Epoch 150] LR: 0.001 - Train Loss: 0.00323 - Test Loss: 0.00346 - Train Accuracy: 88.50% - Test Accuracy: 88.13%\n",
      "Finished Training\n",
      "Best Test accuracy: 88.30\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n---- Start Training ----\")\n",
    "best_accuracy = -1\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # TRAIN THE NETWORK\n",
    "    train_loss, train_correct = 0, 0\n",
    "    net.train()\n",
    "    for inputs, targets in train_loader:\n",
    "        # data is a list of [inputs, labels]\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _, pred = outputs.max(1)  # get the index of the max log-probability\n",
    "        train_correct += pred.eq(targets).sum().item()\n",
    "\n",
    "        # print statistics\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    train_loss /= len(train_loader.dataset)\n",
    "\n",
    "    # TEST NETWORK\n",
    "    net.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            test_loss += criterion(outputs, targets)\n",
    "            _, pred = outputs.max(1)  # get the index of the max log-probability\n",
    "            correct += pred.eq(targets).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        current_lr = param_group['lr']\n",
    "    print(\"[Epoch {}] LR: {:.3f} - Train Loss: {:.5f} - Test Loss: {:.5f} - Train Accuracy: {:.2f}% - Test Accuracy: {:.2f}%\".format(epoch+1, current_lr, train_loss, test_loss, 100. * train_correct / len(train_loader.dataset), test_accuracy))\n",
    "    \n",
    "    if test_accuracy>best_accuracy:\n",
    "        best_accuracy = test_accuracy\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "print('Finished Training')\n",
    "print(\"Best Test accuracy: {:.2f}\".format(best_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
