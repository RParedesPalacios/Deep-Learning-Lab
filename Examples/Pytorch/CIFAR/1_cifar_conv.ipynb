{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "num_classes = 10\n",
    "epochs = 75\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#### LOAD AND TRANSFORM\n",
    "# The output of torchvision datasets are PILImage images of range [0, 1].\n",
    "data_transforms = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10('./data', train=True, download=True, transform=data_transforms)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10('./data', train=False, download=True, transform=data_transforms)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 50000 samples - Max value: 1.0 - Min value: 0.0\n"
     ]
    }
   ],
   "source": [
    "x_batch, y_batch = iter(train_loader).next()\n",
    "print(\"Training set: {} samples - Max value: {} - Min value: {}\".format(len(train_loader.dataset), \n",
    "                                                                        x_batch.max(), x_batch.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: 10000 samples - Max value: 1.0 - Min value: 0.0\n"
     ]
    }
   ],
   "source": [
    "x_batch, y_batch = iter(test_loader).next()\n",
    "print(\"Test set: {} samples - Max value: {} - Min value: {}\".format(len(test_loader.dataset), \n",
    "                                                                        x_batch.max(), x_batch.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example batch shape: torch.Size([100, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "print(\"Example batch shape: {}\".format(x_batch.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNoise(nn.Module):\n",
    "    \"\"\"Gaussian noise regularizer.\n",
    "\n",
    "    Args:\n",
    "        sigma (float, optional): relative standard deviation used to generate the\n",
    "            noise. Relative means that it will be multiplied by the magnitude of\n",
    "            the value your are adding the noise to. This means that sigma can be\n",
    "            the same regardless of the scale of the vector.\n",
    "        is_relative_detach (bool, optional): whether to detach the variable before\n",
    "            computing the scale of the noise. If `False` then the scale of the noise\n",
    "            won't be seen as a constant but something to optimize: this will bias the\n",
    "            network to generate vectors with smaller values.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sigma=0.1, is_relative_detach=True):\n",
    "        super().__init__()\n",
    "        self.sigma = sigma\n",
    "        self.is_relative_detach = is_relative_detach\n",
    "        self.noise = torch.tensor(0).to(device).float()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training and self.sigma != 0:\n",
    "            scale = self.sigma * x.detach() if self.is_relative_detach else self.sigma * x\n",
    "            sampled_noise = self.noise.repeat(*x.size()).normal_() * scale\n",
    "            x = x + sampled_noise\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (block1): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): GaussianNoise()\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (block2): Sequential(\n",
      "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): GaussianNoise()\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (block3): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): GaussianNoise()\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (block4): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): GaussianNoise()\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (block5): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): GaussianNoise()\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (features): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (reluFeatures): ReLU()\n",
      "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.block1 = self._CBGN(3, 32)\n",
    "        self.block2 = self._CBGN(32, 64)\n",
    "        self.block3 = self._CBGN(64, 128)\n",
    "        self.block4 = self._CBGN(128, 256)\n",
    "        self.block5 = self._CBGN(256, 512)\n",
    "        # Flatten at forward!\n",
    "        self.features = nn.Linear(512, 512)\n",
    "        self.reluFeatures = nn.ReLU()\n",
    "        self.classifier = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.block1(x)                         # 32x32 -> 16x16 @ 32\n",
    "        out = self.block2(out)                       # 16x16 -> 8x8 @ 64\n",
    "        out = self.block3(out)                       # 8x8 -> 4x4 @ 128\n",
    "        out = self.block4(out)                       # 4x4 -> 2x2 @ 256\n",
    "        out = self.block5(out)                       # 2x2 -> 1x1 @ 512\n",
    "        out = out.view(out.size(0), -1)              # Flatten\n",
    "        out = self.reluFeatures(self.features(out))  # 512 -> 512\n",
    "        out = self.classifier(out)                   # 512 -> num_classes (10)\n",
    "        return out\n",
    "\n",
    "    # DEF A BLOCK Conv + BN + GN + MaxPool\n",
    "    def _CBGN(self, in_channels, filters):\n",
    "        layers = []\n",
    "        layers += [nn.Conv2d(in_channels, filters, kernel_size=(3,3), padding=1)]\n",
    "        layers += [nn.BatchNorm2d(filters)]\n",
    "        layers += [GaussianNoise(0.3)]\n",
    "        layers += [nn.ReLU()]\n",
    "        layers += [nn.MaxPool2d(kernel_size=(2,2))]\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "net = Net().to(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, weight_decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Start Training ----\n",
      "[Epoch 1] Train Loss: 0.013797 - Test Loss: 0.012904 - Train Accuracy: 49.22% - Test Accuracy: 54.73%\n",
      "[Epoch 2] Train Loss: 0.010004 - Test Loss: 0.009579 - Train Accuracy: 64.45% - Test Accuracy: 66.51%\n",
      "[Epoch 3] Train Loss: 0.008480 - Test Loss: 0.012105 - Train Accuracy: 70.07% - Test Accuracy: 58.71%\n",
      "[Epoch 4] Train Loss: 0.007582 - Test Loss: 0.009332 - Train Accuracy: 73.23% - Test Accuracy: 67.58%\n",
      "[Epoch 5] Train Loss: 0.006883 - Test Loss: 0.014690 - Train Accuracy: 75.80% - Test Accuracy: 52.33%\n",
      "[Epoch 6] Train Loss: 0.006376 - Test Loss: 0.008274 - Train Accuracy: 77.36% - Test Accuracy: 71.31%\n",
      "[Epoch 7] Train Loss: 0.005888 - Test Loss: 0.007582 - Train Accuracy: 79.18% - Test Accuracy: 73.26%\n",
      "[Epoch 8] Train Loss: 0.005493 - Test Loss: 0.008150 - Train Accuracy: 80.72% - Test Accuracy: 72.41%\n",
      "[Epoch 9] Train Loss: 0.005199 - Test Loss: 0.007257 - Train Accuracy: 81.80% - Test Accuracy: 75.38%\n",
      "[Epoch 10] Train Loss: 0.004849 - Test Loss: 0.007638 - Train Accuracy: 82.93% - Test Accuracy: 73.97%\n",
      "[Epoch 11] Train Loss: 0.004549 - Test Loss: 0.007654 - Train Accuracy: 83.88% - Test Accuracy: 74.17%\n",
      "[Epoch 12] Train Loss: 0.004347 - Test Loss: 0.008321 - Train Accuracy: 84.58% - Test Accuracy: 72.92%\n",
      "[Epoch 13] Train Loss: 0.004077 - Test Loss: 0.008073 - Train Accuracy: 85.53% - Test Accuracy: 73.64%\n",
      "[Epoch 14] Train Loss: 0.003844 - Test Loss: 0.006584 - Train Accuracy: 86.30% - Test Accuracy: 78.13%\n",
      "[Epoch 15] Train Loss: 0.003661 - Test Loss: 0.007466 - Train Accuracy: 87.02% - Test Accuracy: 75.10%\n",
      "[Epoch 16] Train Loss: 0.003493 - Test Loss: 0.006984 - Train Accuracy: 87.43% - Test Accuracy: 76.73%\n",
      "[Epoch 17] Train Loss: 0.003267 - Test Loss: 0.006391 - Train Accuracy: 88.44% - Test Accuracy: 78.29%\n",
      "[Epoch 18] Train Loss: 0.003115 - Test Loss: 0.008496 - Train Accuracy: 88.83% - Test Accuracy: 73.83%\n",
      "[Epoch 19] Train Loss: 0.002961 - Test Loss: 0.008591 - Train Accuracy: 89.41% - Test Accuracy: 74.76%\n",
      "[Epoch 20] Train Loss: 0.002819 - Test Loss: 0.007417 - Train Accuracy: 89.93% - Test Accuracy: 77.19%\n",
      "[Epoch 21] Train Loss: 0.002696 - Test Loss: 0.007230 - Train Accuracy: 90.30% - Test Accuracy: 77.02%\n",
      "[Epoch 22] Train Loss: 0.002551 - Test Loss: 0.007202 - Train Accuracy: 90.75% - Test Accuracy: 76.88%\n",
      "[Epoch 23] Train Loss: 0.002453 - Test Loss: 0.008268 - Train Accuracy: 91.27% - Test Accuracy: 75.13%\n",
      "[Epoch 24] Train Loss: 0.002309 - Test Loss: 0.012245 - Train Accuracy: 91.54% - Test Accuracy: 68.51%\n",
      "[Epoch 25] Train Loss: 0.002198 - Test Loss: 0.007318 - Train Accuracy: 92.17% - Test Accuracy: 77.49%\n",
      "[Epoch 26] Train Loss: 0.002126 - Test Loss: 0.006607 - Train Accuracy: 92.32% - Test Accuracy: 79.53%\n",
      "[Epoch 27] Train Loss: 0.002009 - Test Loss: 0.008854 - Train Accuracy: 92.83% - Test Accuracy: 74.42%\n",
      "[Epoch 28] Train Loss: 0.001944 - Test Loss: 0.007271 - Train Accuracy: 93.04% - Test Accuracy: 78.71%\n",
      "[Epoch 29] Train Loss: 0.001867 - Test Loss: 0.008432 - Train Accuracy: 93.29% - Test Accuracy: 75.94%\n",
      "[Epoch 30] Train Loss: 0.001778 - Test Loss: 0.008310 - Train Accuracy: 93.63% - Test Accuracy: 76.37%\n",
      "[Epoch 31] Train Loss: 0.001733 - Test Loss: 0.008721 - Train Accuracy: 93.73% - Test Accuracy: 75.78%\n",
      "[Epoch 32] Train Loss: 0.001650 - Test Loss: 0.009345 - Train Accuracy: 94.09% - Test Accuracy: 75.16%\n",
      "[Epoch 33] Train Loss: 0.001616 - Test Loss: 0.007481 - Train Accuracy: 94.27% - Test Accuracy: 79.15%\n",
      "[Epoch 34] Train Loss: 0.001544 - Test Loss: 0.007789 - Train Accuracy: 94.43% - Test Accuracy: 78.55%\n",
      "[Epoch 35] Train Loss: 0.001450 - Test Loss: 0.009117 - Train Accuracy: 94.85% - Test Accuracy: 76.70%\n",
      "[Epoch 36] Train Loss: 0.001478 - Test Loss: 0.009567 - Train Accuracy: 94.73% - Test Accuracy: 75.69%\n",
      "[Epoch 37] Train Loss: 0.001363 - Test Loss: 0.008174 - Train Accuracy: 95.14% - Test Accuracy: 78.72%\n",
      "[Epoch 38] Train Loss: 0.001337 - Test Loss: 0.007445 - Train Accuracy: 95.19% - Test Accuracy: 79.85%\n",
      "[Epoch 39] Train Loss: 0.001278 - Test Loss: 0.007006 - Train Accuracy: 95.50% - Test Accuracy: 81.40%\n",
      "[Epoch 40] Train Loss: 0.001258 - Test Loss: 0.007903 - Train Accuracy: 95.53% - Test Accuracy: 79.37%\n",
      "[Epoch 41] Train Loss: 0.001234 - Test Loss: 0.007767 - Train Accuracy: 95.56% - Test Accuracy: 80.03%\n",
      "[Epoch 42] Train Loss: 0.001176 - Test Loss: 0.007656 - Train Accuracy: 95.81% - Test Accuracy: 80.20%\n",
      "[Epoch 43] Train Loss: 0.001110 - Test Loss: 0.010354 - Train Accuracy: 96.15% - Test Accuracy: 75.07%\n",
      "[Epoch 44] Train Loss: 0.001150 - Test Loss: 0.009507 - Train Accuracy: 95.90% - Test Accuracy: 76.90%\n",
      "[Epoch 45] Train Loss: 0.001082 - Test Loss: 0.009085 - Train Accuracy: 96.13% - Test Accuracy: 77.62%\n",
      "[Epoch 46] Train Loss: 0.001077 - Test Loss: 0.009949 - Train Accuracy: 96.17% - Test Accuracy: 76.39%\n",
      "[Epoch 47] Train Loss: 0.001028 - Test Loss: 0.007194 - Train Accuracy: 96.34% - Test Accuracy: 81.58%\n",
      "[Epoch 48] Train Loss: 0.000987 - Test Loss: 0.008185 - Train Accuracy: 96.47% - Test Accuracy: 79.80%\n",
      "[Epoch 49] Train Loss: 0.000985 - Test Loss: 0.009025 - Train Accuracy: 96.46% - Test Accuracy: 78.31%\n",
      "[Epoch 50] Train Loss: 0.000951 - Test Loss: 0.007656 - Train Accuracy: 96.59% - Test Accuracy: 80.87%\n",
      "[Epoch 51] Train Loss: 0.000941 - Test Loss: 0.007981 - Train Accuracy: 96.69% - Test Accuracy: 80.53%\n",
      "[Epoch 52] Train Loss: 0.000884 - Test Loss: 0.009143 - Train Accuracy: 96.81% - Test Accuracy: 78.80%\n",
      "[Epoch 53] Train Loss: 0.000881 - Test Loss: 0.008166 - Train Accuracy: 96.87% - Test Accuracy: 80.65%\n",
      "[Epoch 54] Train Loss: 0.000875 - Test Loss: 0.010351 - Train Accuracy: 96.92% - Test Accuracy: 76.74%\n",
      "[Epoch 55] Train Loss: 0.000850 - Test Loss: 0.010497 - Train Accuracy: 96.98% - Test Accuracy: 76.66%\n",
      "[Epoch 56] Train Loss: 0.000855 - Test Loss: 0.008263 - Train Accuracy: 96.93% - Test Accuracy: 80.27%\n",
      "[Epoch 57] Train Loss: 0.000819 - Test Loss: 0.009243 - Train Accuracy: 97.04% - Test Accuracy: 79.34%\n",
      "[Epoch 58] Train Loss: 0.000768 - Test Loss: 0.007388 - Train Accuracy: 97.19% - Test Accuracy: 81.42%\n",
      "[Epoch 59] Train Loss: 0.000766 - Test Loss: 0.009943 - Train Accuracy: 97.29% - Test Accuracy: 78.72%\n",
      "[Epoch 60] Train Loss: 0.000764 - Test Loss: 0.008787 - Train Accuracy: 97.28% - Test Accuracy: 80.37%\n",
      "[Epoch 61] Train Loss: 0.000752 - Test Loss: 0.008280 - Train Accuracy: 97.31% - Test Accuracy: 80.50%\n",
      "[Epoch 62] Train Loss: 0.000712 - Test Loss: 0.009801 - Train Accuracy: 97.44% - Test Accuracy: 78.58%\n",
      "[Epoch 63] Train Loss: 0.000733 - Test Loss: 0.008562 - Train Accuracy: 97.48% - Test Accuracy: 79.92%\n",
      "[Epoch 64] Train Loss: 0.000688 - Test Loss: 0.008418 - Train Accuracy: 97.57% - Test Accuracy: 80.70%\n",
      "[Epoch 65] Train Loss: 0.000693 - Test Loss: 0.009095 - Train Accuracy: 97.52% - Test Accuracy: 79.30%\n",
      "[Epoch 66] Train Loss: 0.000692 - Test Loss: 0.010455 - Train Accuracy: 97.59% - Test Accuracy: 77.63%\n",
      "[Epoch 67] Train Loss: 0.000669 - Test Loss: 0.011198 - Train Accuracy: 97.71% - Test Accuracy: 75.35%\n",
      "[Epoch 68] Train Loss: 0.000651 - Test Loss: 0.009919 - Train Accuracy: 97.70% - Test Accuracy: 78.95%\n",
      "[Epoch 69] Train Loss: 0.000614 - Test Loss: 0.009289 - Train Accuracy: 97.84% - Test Accuracy: 80.83%\n",
      "[Epoch 70] Train Loss: 0.000642 - Test Loss: 0.008274 - Train Accuracy: 97.68% - Test Accuracy: 81.53%\n",
      "[Epoch 71] Train Loss: 0.000584 - Test Loss: 0.009989 - Train Accuracy: 97.88% - Test Accuracy: 78.41%\n",
      "[Epoch 72] Train Loss: 0.000619 - Test Loss: 0.010633 - Train Accuracy: 97.82% - Test Accuracy: 77.78%\n",
      "[Epoch 73] Train Loss: 0.000611 - Test Loss: 0.008056 - Train Accuracy: 97.85% - Test Accuracy: 81.59%\n",
      "[Epoch 74] Train Loss: 0.000584 - Test Loss: 0.013216 - Train Accuracy: 97.94% - Test Accuracy: 74.66%\n",
      "[Epoch 75] Train Loss: 0.000554 - Test Loss: 0.008979 - Train Accuracy: 98.09% - Test Accuracy: 80.93%\n",
      "Finished Training\n",
      "Best Test accuracy: 81.59\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n---- Start Training ----\")\n",
    "best_accuracy = -1\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # TRAIN THE NETWORK\n",
    "    train_loss, train_correct = 0, 0\n",
    "    net.train()\n",
    "    for inputs, targets in train_loader:\n",
    "        # data is a list of [inputs, labels]\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _, pred = outputs.max(1)  # get the index of the max log-probability\n",
    "        train_correct += pred.eq(targets).sum().item()\n",
    "\n",
    "        # print statistics\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    train_loss /= len(train_loader.dataset)\n",
    "\n",
    "    # TEST NETWORK\n",
    "    net.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            test_loss += criterion(outputs, targets)\n",
    "            _, pred = outputs.max(1)  # get the index of the max log-probability\n",
    "            correct += pred.eq(targets).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    print(\"[Epoch {}] Train Loss: {:.6f} - Test Loss: {:.6f} - Train Accuracy: {:.2f}% - Test Accuracy: {:.2f}%\".format(epoch+1, train_loss, test_loss, 100. * train_correct / len(train_loader.dataset), test_accuracy))\n",
    "    \n",
    "    if test_accuracy>best_accuracy:\n",
    "        best_accuracy = test_accuracy\n",
    "    \n",
    "print('Finished Training')\n",
    "print(\"Best Test accuracy: {:.2f}\".format(best_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
