{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "num_classes = 10\n",
    "epochs = 150\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#### LOAD AND TRANSFORM\n",
    "# The output of torchvision datasets are PILImage images of range [0, 1].\n",
    "# https://pytorch.org/docs/stable/torchvision/transforms.html\n",
    "train_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomAffine(degrees=20, translate=(0.2, 0.2), scale=(1.0, 1.2)),\n",
    "    torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10('./data', train=True, download=True, transform=train_transforms)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "test_transforms = torchvision.transforms.Compose([\n",
    "                        torchvision.transforms.ToTensor(),\n",
    "                        torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "                  ])\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10('./data', train=False, download=True, transform=test_transforms)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 50000 samples - Max value: 2.7537312507629395 - Min value: -2.429065704345703\n"
     ]
    }
   ],
   "source": [
    "x_batch, y_batch = iter(train_loader).next()\n",
    "print(\"Training set: {} samples - Max value: {} - Min value: {}\".format(len(train_loader.dataset), \n",
    "                                                                        x_batch.max(), x_batch.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: 10000 samples - Max value: 2.7537312507629395 - Min value: -2.429065704345703\n"
     ]
    }
   ],
   "source": [
    "x_batch, y_batch = iter(test_loader).next()\n",
    "print(\"Test set: {} samples - Max value: {} - Min value: {}\".format(len(test_loader.dataset), \n",
    "                                                                        x_batch.max(), x_batch.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example batch shape: torch.Size([100, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "print(\"Example batch shape: {}\".format(x_batch.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNoise(nn.Module):\n",
    "    \"\"\"Gaussian noise regularizer.\n",
    "\n",
    "    Args:\n",
    "        sigma (float, optional): relative standard deviation used to generate the\n",
    "            noise. Relative means that it will be multiplied by the magnitude of\n",
    "            the value your are adding the noise to. This means that sigma can be\n",
    "            the same regardless of the scale of the vector.\n",
    "        is_relative_detach (bool, optional): whether to detach the variable before\n",
    "            computing the scale of the noise. If `False` then the scale of the noise\n",
    "            won't be seen as a constant but something to optimize: this will bias the\n",
    "            network to generate vectors with smaller values.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sigma=0.1, is_relative_detach=True):\n",
    "        super().__init__()\n",
    "        self.sigma = sigma\n",
    "        self.is_relative_detach = is_relative_detach\n",
    "        self.noise = torch.tensor(0).to(device).float()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training and self.sigma != 0:\n",
    "            scale = self.sigma * x.detach() if self.is_relative_detach else self.sigma * x\n",
    "            sampled_noise = self.noise.repeat(*x.size()).normal_() * scale\n",
    "            x = x + sampled_noise\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet18, self).__init__()\n",
    "        #resnet connection at forward\n",
    "        \n",
    "        # Initial convolution before resnet blocks\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        ########## 32x32@64\n",
    "        #RESNET BLOCK 1\n",
    "        self.b1_conv1 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.b1_bn1 = nn.BatchNorm2d(64)\n",
    "        self.b1_conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.b1_bn2 = nn.BatchNorm2d(64)\n",
    "        #RESNET BLOCK 2\n",
    "        self.b2_conv1 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.b2_bn1 = nn.BatchNorm2d(64)\n",
    "        self.b2_conv2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.b2_bn2 = nn.BatchNorm2d(64)\n",
    "\n",
    "\n",
    "        ########## 16x16@128\n",
    "        #RESNET BLOCK 3 \n",
    "        #we need to readapt the input map using 1x1 convolution kernel (like a MLP combining channel dimensions)\n",
    "        self.b3_shortcut = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=1, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(128)\n",
    "        )\n",
    "        self.b3_conv1 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.b3_bn1 = nn.BatchNorm2d(128)\n",
    "        self.b3_conv2 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.b3_bn2 = nn.BatchNorm2d(128)\n",
    "        #RESNET BLOCK 4\n",
    "        self.b4_conv1 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.b4_bn1 = nn.BatchNorm2d(128)\n",
    "        self.b4_conv2 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.b4_bn2 = nn.BatchNorm2d(128)\n",
    "\n",
    "        \n",
    "        ########## 8x8@256\n",
    "        #RESNET BLOCK 5\n",
    "        #we need to readapt the input map using 1x1 convolution kernel (like a MLP combining channel dimensions)\n",
    "        self.b5_shortcut = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=1, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(256)\n",
    "        )\n",
    "        self.b5_conv1 = nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.b5_bn1 = nn.BatchNorm2d(256)\n",
    "        self.b5_conv2 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.b5_bn2 = nn.BatchNorm2d(256)\n",
    "        #RESNET BLOCK 6\n",
    "        self.b6_conv1 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.b6_bn1 = nn.BatchNorm2d(256)\n",
    "        self.b6_conv2 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.b6_bn2 = nn.BatchNorm2d(256)\n",
    "\n",
    "\n",
    "        ########## 4x4@512\n",
    "        #RESNET BLOCK 7\n",
    "        #we need to readapt the input map using 1x1 convolution kernel (like a MLP combining channel dimensions)\n",
    "        self.b7_shortcut = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, kernel_size=1, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(512)\n",
    "        )\n",
    "        self.b7_conv1 = nn.Conv2d(256, 512, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.b7_bn1 = nn.BatchNorm2d(512)\n",
    "        self.b7_conv2 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.b7_bn2 = nn.BatchNorm2d(512)\n",
    "        #RESNET BLOCK 8\n",
    "        self.b8_conv1 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.b8_bn1 = nn.BatchNorm2d(512)\n",
    "        self.b8_conv2 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.b8_bn2 = nn.BatchNorm2d(512)\n",
    "\n",
    "        ########## 1x1@512\n",
    "        # Final pooling\n",
    "        self.average_pooling=nn.AvgPool2d(4)\n",
    "\n",
    "        ########## 512@num_classes\n",
    "        #To connect to the number of classes\n",
    "        self.Linear=nn.Linear(512, num_classes)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #### 32x32@3 -> 32x32@64\n",
    "        # 0. Initial convolution ==> \n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "\n",
    "        #### 32x32@64 -> 32x32@64\n",
    "        # 1. First ResNet block\n",
    "        b1_1 = F.relu(self.b1_bn1(self.b1_conv1(x)))\n",
    "        b1_2 = self.b1_bn2(self.b1_conv2(b1_1))\n",
    "        out1 = F.relu(x + b1_2) # resnet connection plus activation\n",
    "        # 2. Second ResNet block\n",
    "        b2_1 = F.relu(self.b2_bn1(self.b2_conv1(out1)))\n",
    "        b2_2 = self.b2_bn2(self.b2_conv2(b2_1))\n",
    "        out2 = F.relu(out1 + b2_2) # resnet connection plus activation\n",
    "\n",
    "        #### 32x32@64 -> 16x16@128\n",
    "        # 3. Third ResNet block\n",
    "        # we need to readapt the number of maps of the input so it matches the output\n",
    "        shortcut = self.b3_shortcut(out2)\n",
    "        b3_1 = F.relu(self.b3_bn1(self.b3_conv1(out2)))\n",
    "        b3_2 = self.b3_bn2(self.b3_conv2(b3_1))\n",
    "        out3 = F.relu(shortcut + b3_2) #resnet connection plus activation\n",
    "        # 4. Fourth ResNet block\n",
    "        b4_1 = F.relu(self.b4_bn1(self.b4_conv1(out3)))\n",
    "        b4_2 = self.b4_bn2(self.b4_conv2(b4_1))\n",
    "        out4 = F.relu(out3 + b4_2) #resnet connection plus activation\n",
    "\n",
    "        #### 16x16@128 -> 8x8@256\n",
    "        # 5. Fifth ResNet block\n",
    "        # we need to readapt the number of maps of the input so it matches the output\n",
    "        shortcut = self.b5_shortcut(out4)\n",
    "        b5_1 = F.relu(self.b5_bn1(self.b5_conv1(out4)))\n",
    "        b5_2 = self.b5_bn2(self.b5_conv2(b5_1))\n",
    "        out5 = F.relu(shortcut + b5_2) #resnet connection plus activation\n",
    "        # 6. Sixth ResNet block\n",
    "        b6_1 = F.relu(self.b6_bn1(self.b6_conv1(out5)))\n",
    "        b6_2 = self.b6_bn2(self.b6_conv2(b6_1))\n",
    "        out6 = F.relu(out5 + b6_2) #resnet connection plus activation\n",
    "\n",
    "        #### 8x8@256 -> 4x4@512\n",
    "        # 7. Seventh ResNet block\n",
    "        # we need to readapt the number of maps of the input so it matches the output\n",
    "        shortcut = self.b7_shortcut(out6)\n",
    "        b7_1 = F.relu(self.b7_bn1(self.b7_conv1(out6)))\n",
    "        b7_2 = self.b7_bn2(self.b7_conv2(b7_1))\n",
    "        out7 = F.relu(shortcut + b7_2) #resnet connection plus activation\n",
    "        # 8. Eigth ResNet block\n",
    "        b8_1 = F.relu(self.b8_bn1(self.b8_conv1(out7)))\n",
    "        b8_2 = self.b8_bn2(self.b8_conv2(b8_1))\n",
    "        out8 = F.relu(out7 + b8_2) #resnet connection plus activation\n",
    "\n",
    "        #### 4x4@512 -> 1x1@512\n",
    "        pool_out = self.average_pooling(out8)\n",
    "\n",
    "        #### 512 -> num_classes\n",
    "        fc_out = self.Linear(pool_out.view(pool_out.size(0),-1))\n",
    "\n",
    "        return fc_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet18(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (b1_conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (b1_bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (b1_conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (b1_bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (b2_conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (b2_bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (b2_conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (b2_bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (b3_shortcut): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (b3_conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (b3_bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (b3_conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (b3_bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (b4_conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (b4_bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (b4_conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (b4_bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (b5_shortcut): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (b5_conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (b5_bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (b5_conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (b5_bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (b6_conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (b6_bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (b6_conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (b6_bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (b7_shortcut): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (b7_conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (b7_bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (b7_conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (b7_bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (b8_conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (b8_bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (b8_conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (b8_bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (average_pooling): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
      "  (Linear): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = ResNet18().to(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, weight_decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = 0.1     if epoch < 50\n",
    "# lr = 0.01    if 30 <= epoch < 100\n",
    "# lr = 0.001   if epoch >= 100\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50, 100], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Start Training ----\n",
      "[Epoch 1] LR: 0.100 - Train Loss: 0.01595 - Test Loss: 0.01265 - Train Accuracy: 41.24% - Test Accuracy: 53.64%\n",
      "[Epoch 2] LR: 0.100 - Train Loss: 0.01148 - Test Loss: 0.01091 - Train Accuracy: 58.74% - Test Accuracy: 61.43%\n",
      "[Epoch 3] LR: 0.100 - Train Loss: 0.00952 - Test Loss: 0.00957 - Train Accuracy: 66.34% - Test Accuracy: 67.83%\n",
      "[Epoch 4] LR: 0.100 - Train Loss: 0.00824 - Test Loss: 0.00805 - Train Accuracy: 71.12% - Test Accuracy: 71.73%\n",
      "[Epoch 5] LR: 0.100 - Train Loss: 0.00737 - Test Loss: 0.00766 - Train Accuracy: 74.24% - Test Accuracy: 73.17%\n",
      "[Epoch 6] LR: 0.100 - Train Loss: 0.00673 - Test Loss: 0.00728 - Train Accuracy: 76.68% - Test Accuracy: 75.19%\n",
      "[Epoch 7] LR: 0.100 - Train Loss: 0.00626 - Test Loss: 0.00591 - Train Accuracy: 78.06% - Test Accuracy: 79.96%\n",
      "[Epoch 8] LR: 0.100 - Train Loss: 0.00584 - Test Loss: 0.00617 - Train Accuracy: 79.76% - Test Accuracy: 79.22%\n",
      "[Epoch 9] LR: 0.100 - Train Loss: 0.00549 - Test Loss: 0.00582 - Train Accuracy: 80.85% - Test Accuracy: 80.73%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-c6761b09aa39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# get the index of the max log-probability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mtrain_correct\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# print statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"\\n---- Start Training ----\")\n",
    "best_accuracy = -1\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # TRAIN THE NETWORK\n",
    "    train_loss, train_correct = 0, 0\n",
    "    net.train()\n",
    "    for inputs, targets in train_loader:\n",
    "        # data is a list of [inputs, labels]\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _, pred = outputs.max(1)  # get the index of the max log-probability\n",
    "        train_correct += pred.eq(targets).sum().item()\n",
    "\n",
    "        # print statistics\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    train_loss /= len(train_loader.dataset)\n",
    "\n",
    "    # TEST NETWORK\n",
    "    net.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            test_loss += criterion(outputs, targets)\n",
    "            _, pred = outputs.max(1)  # get the index of the max log-probability\n",
    "            correct += pred.eq(targets).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        current_lr = param_group['lr']\n",
    "    print(\"[Epoch {}] LR: {:.3f} - Train Loss: {:.5f} - Test Loss: {:.5f} - Train Accuracy: {:.2f}% - Test Accuracy: {:.2f}%\".format(epoch+1, current_lr, train_loss, test_loss, 100. * train_correct / len(train_loader.dataset), test_accuracy))\n",
    "    \n",
    "    if test_accuracy>best_accuracy:\n",
    "        best_accuracy = test_accuracy\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "print('Finished Training')\n",
    "print(\"Best Test accuracy: {:.2f}\".format(best_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
