{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "epochs = 75\n",
    "num_classes=10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### LOAD AND TRANSFORM\n",
    "# The output of torchvision datasets are PILImage images of range [0, 1].\n",
    "# https://pytorch.org/docs/stable/torchvision/transforms.html\n",
    "train_transforms = torchvision.transforms.Compose([torchvision.transforms.RandomHorizontalFlip(p=0.0),\n",
    "                                                   torchvision.transforms.RandomAffine(degrees=3, translate=(0.1, 0.1)),\n",
    "                                                   torchvision.transforms.ToTensor()])\n",
    "\n",
    "train_set = torchvision.datasets.MNIST('.data/', train=True, download=True, transform=train_transforms)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_transforms = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "\n",
    "test_set = torchvision.datasets.MNIST('.data/', train=False, download=True, transform=test_transforms)\n",
    "test_loader = torch.utils.data.DataLoader(test_set,batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 60000 samples - Max value: 1.0 - Min value: 0.0\n"
     ]
    }
   ],
   "source": [
    "x_batch, y_batch = iter(train_loader).next()\n",
    "print(\"Training set: {} samples - Max value: {} - Min value: {}\".format(len(train_loader.dataset), \n",
    "                                                                        x_batch.max(), x_batch.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: 10000 samples - Max value: 1.0 - Min value: 0.0\n"
     ]
    }
   ],
   "source": [
    "x_batch, y_batch = iter(test_loader).next()\n",
    "print(\"Test set: {} samples - Max value: {} - Min value: {}\".format(len(test_loader.dataset), \n",
    "                                                                        x_batch.max(), x_batch.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example batch shape: torch.Size([100, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(\"Example batch shape: {}\".format(x_batch.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNoise(nn.Module):\n",
    "    \"\"\"Gaussian noise regularizer.\n",
    "\n",
    "    Args:\n",
    "        sigma (float, optional): relative standard deviation used to generate the\n",
    "            noise. Relative means that it will be multiplied by the magnitude of\n",
    "            the value your are adding the noise to. This means that sigma can be\n",
    "            the same regardless of the scale of the vector.\n",
    "        is_relative_detach (bool, optional): whether to detach the variable before\n",
    "            computing the scale of the noise. If `False` then the scale of the noise\n",
    "            won't be seen as a constant but something to optimize: this will bias the\n",
    "            network to generate vectors with smaller values.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sigma=0.1, is_relative_detach=True):\n",
    "        super().__init__()\n",
    "        self.sigma = sigma\n",
    "        self.is_relative_detach = is_relative_detach\n",
    "        self.noise = torch.tensor(0).to(device).float()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training and self.sigma != 0:\n",
    "            scale = self.sigma * x.detach() if self.is_relative_detach else self.sigma * x\n",
    "            sampled_noise = self.noise.repeat(*x.size()).normal_() * scale\n",
    "            x = x + sampled_noise\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (gn0): GaussianNoise()\n",
      "  (linear1): Linear(in_features=784, out_features=1024, bias=True)\n",
      "  (bn1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gn1): GaussianNoise()\n",
      "  (relu1): ReLU()\n",
      "  (linear2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (bn2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gn2): GaussianNoise()\n",
      "  (relu2): ReLU()\n",
      "  (linear3): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (gn3): GaussianNoise()\n",
      "  (relu3): ReLU()\n",
      "  (classifier): Linear(in_features=1024, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.gn0 = GaussianNoise(0.3)\n",
    "        self.linear1 = nn.Linear(784, 1024)\n",
    "        self.bn1 = nn.BatchNorm1d(1024)\n",
    "        self.gn1 = GaussianNoise(0.3)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(1024, 1024)\n",
    "        self.bn2 = nn.BatchNorm1d(1024)\n",
    "        self.gn2 = GaussianNoise(0.3)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.linear3 = nn.Linear(1024, 1024)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.gn3 = GaussianNoise(0.3)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.classifier = nn.Linear(1024, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.gn0(x)\n",
    "        out = self.relu1(self.gn1(self.bn1(self.linear1(out))))\n",
    "        out = self.relu2(self.bn2(self.linear2(out)))\n",
    "        out = self.relu3(self.bn3(self.linear3(out)))\n",
    "        out = self.classifier(out)       \n",
    "        return out\n",
    "\n",
    "net = Net().to(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = 0.1     if epoch < 25\n",
    "# lr = 0.01    if 30 <= epoch < 50\n",
    "# lr = 0.001   if epoch >= 50\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[25, 50], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Start Training ----\n",
      "[Epoch 1] LR: 0.100 - Train Loss: 0.00388 - Test Loss: 0.00094 - Train Accuracy: 87.83% - Test Accuracy: 96.95%\n",
      "[Epoch 2] LR: 0.100 - Train Loss: 0.00182 - Test Loss: 0.00072 - Train Accuracy: 94.13% - Test Accuracy: 97.61%\n",
      "[Epoch 3] LR: 0.100 - Train Loss: 0.00148 - Test Loss: 0.00063 - Train Accuracy: 95.23% - Test Accuracy: 97.89%\n",
      "[Epoch 4] LR: 0.100 - Train Loss: 0.00129 - Test Loss: 0.00053 - Train Accuracy: 95.89% - Test Accuracy: 98.32%\n",
      "[Epoch 5] LR: 0.100 - Train Loss: 0.00115 - Test Loss: 0.00048 - Train Accuracy: 96.30% - Test Accuracy: 98.42%\n",
      "[Epoch 6] LR: 0.100 - Train Loss: 0.00106 - Test Loss: 0.00048 - Train Accuracy: 96.68% - Test Accuracy: 98.46%\n",
      "[Epoch 7] LR: 0.100 - Train Loss: 0.00101 - Test Loss: 0.00050 - Train Accuracy: 96.80% - Test Accuracy: 98.26%\n",
      "[Epoch 8] LR: 0.100 - Train Loss: 0.00095 - Test Loss: 0.00041 - Train Accuracy: 96.95% - Test Accuracy: 98.56%\n",
      "[Epoch 9] LR: 0.100 - Train Loss: 0.00085 - Test Loss: 0.00041 - Train Accuracy: 97.22% - Test Accuracy: 98.64%\n",
      "[Epoch 10] LR: 0.100 - Train Loss: 0.00079 - Test Loss: 0.00037 - Train Accuracy: 97.39% - Test Accuracy: 98.75%\n",
      "[Epoch 11] LR: 0.100 - Train Loss: 0.00077 - Test Loss: 0.00037 - Train Accuracy: 97.50% - Test Accuracy: 98.69%\n",
      "[Epoch 12] LR: 0.100 - Train Loss: 0.00077 - Test Loss: 0.00034 - Train Accuracy: 97.56% - Test Accuracy: 98.81%\n",
      "[Epoch 13] LR: 0.100 - Train Loss: 0.00070 - Test Loss: 0.00041 - Train Accuracy: 97.74% - Test Accuracy: 98.65%\n",
      "[Epoch 14] LR: 0.100 - Train Loss: 0.00071 - Test Loss: 0.00036 - Train Accuracy: 97.73% - Test Accuracy: 98.83%\n",
      "[Epoch 15] LR: 0.100 - Train Loss: 0.00068 - Test Loss: 0.00031 - Train Accuracy: 97.79% - Test Accuracy: 98.98%\n",
      "[Epoch 16] LR: 0.100 - Train Loss: 0.00065 - Test Loss: 0.00034 - Train Accuracy: 97.89% - Test Accuracy: 98.88%\n",
      "[Epoch 17] LR: 0.100 - Train Loss: 0.00065 - Test Loss: 0.00035 - Train Accuracy: 97.85% - Test Accuracy: 98.81%\n",
      "[Epoch 18] LR: 0.100 - Train Loss: 0.00062 - Test Loss: 0.00034 - Train Accuracy: 97.99% - Test Accuracy: 98.82%\n",
      "[Epoch 19] LR: 0.100 - Train Loss: 0.00058 - Test Loss: 0.00028 - Train Accuracy: 98.11% - Test Accuracy: 99.01%\n",
      "[Epoch 20] LR: 0.100 - Train Loss: 0.00061 - Test Loss: 0.00031 - Train Accuracy: 98.05% - Test Accuracy: 99.01%\n",
      "[Epoch 21] LR: 0.100 - Train Loss: 0.00058 - Test Loss: 0.00030 - Train Accuracy: 98.18% - Test Accuracy: 98.95%\n",
      "[Epoch 22] LR: 0.100 - Train Loss: 0.00055 - Test Loss: 0.00033 - Train Accuracy: 98.20% - Test Accuracy: 98.93%\n",
      "[Epoch 23] LR: 0.100 - Train Loss: 0.00056 - Test Loss: 0.00032 - Train Accuracy: 98.16% - Test Accuracy: 98.95%\n",
      "[Epoch 24] LR: 0.100 - Train Loss: 0.00052 - Test Loss: 0.00029 - Train Accuracy: 98.30% - Test Accuracy: 99.02%\n",
      "[Epoch 25] LR: 0.100 - Train Loss: 0.00052 - Test Loss: 0.00030 - Train Accuracy: 98.29% - Test Accuracy: 98.92%\n",
      "[Epoch 26] LR: 0.100 - Train Loss: 0.00052 - Test Loss: 0.00028 - Train Accuracy: 98.32% - Test Accuracy: 99.03%\n",
      "[Epoch 27] LR: 0.010 - Train Loss: 0.00044 - Test Loss: 0.00026 - Train Accuracy: 98.61% - Test Accuracy: 99.11%\n",
      "[Epoch 28] LR: 0.010 - Train Loss: 0.00040 - Test Loss: 0.00025 - Train Accuracy: 98.72% - Test Accuracy: 99.10%\n",
      "[Epoch 29] LR: 0.010 - Train Loss: 0.00040 - Test Loss: 0.00024 - Train Accuracy: 98.68% - Test Accuracy: 99.18%\n",
      "[Epoch 30] LR: 0.010 - Train Loss: 0.00039 - Test Loss: 0.00024 - Train Accuracy: 98.78% - Test Accuracy: 99.12%\n",
      "[Epoch 31] LR: 0.010 - Train Loss: 0.00038 - Test Loss: 0.00023 - Train Accuracy: 98.75% - Test Accuracy: 99.22%\n",
      "[Epoch 32] LR: 0.010 - Train Loss: 0.00038 - Test Loss: 0.00023 - Train Accuracy: 98.79% - Test Accuracy: 99.16%\n",
      "[Epoch 33] LR: 0.010 - Train Loss: 0.00037 - Test Loss: 0.00023 - Train Accuracy: 98.86% - Test Accuracy: 99.14%\n",
      "[Epoch 34] LR: 0.010 - Train Loss: 0.00035 - Test Loss: 0.00023 - Train Accuracy: 98.88% - Test Accuracy: 99.18%\n",
      "[Epoch 35] LR: 0.010 - Train Loss: 0.00036 - Test Loss: 0.00022 - Train Accuracy: 98.80% - Test Accuracy: 99.18%\n",
      "[Epoch 36] LR: 0.010 - Train Loss: 0.00035 - Test Loss: 0.00023 - Train Accuracy: 98.94% - Test Accuracy: 99.14%\n",
      "[Epoch 37] LR: 0.010 - Train Loss: 0.00034 - Test Loss: 0.00022 - Train Accuracy: 98.90% - Test Accuracy: 99.23%\n",
      "[Epoch 38] LR: 0.010 - Train Loss: 0.00037 - Test Loss: 0.00022 - Train Accuracy: 98.82% - Test Accuracy: 99.21%\n",
      "[Epoch 39] LR: 0.010 - Train Loss: 0.00034 - Test Loss: 0.00022 - Train Accuracy: 98.95% - Test Accuracy: 99.20%\n",
      "[Epoch 40] LR: 0.010 - Train Loss: 0.00034 - Test Loss: 0.00023 - Train Accuracy: 98.94% - Test Accuracy: 99.23%\n",
      "[Epoch 41] LR: 0.010 - Train Loss: 0.00035 - Test Loss: 0.00022 - Train Accuracy: 98.84% - Test Accuracy: 99.22%\n",
      "[Epoch 42] LR: 0.010 - Train Loss: 0.00034 - Test Loss: 0.00022 - Train Accuracy: 98.92% - Test Accuracy: 99.19%\n",
      "[Epoch 43] LR: 0.010 - Train Loss: 0.00034 - Test Loss: 0.00022 - Train Accuracy: 98.87% - Test Accuracy: 99.20%\n",
      "[Epoch 44] LR: 0.010 - Train Loss: 0.00033 - Test Loss: 0.00022 - Train Accuracy: 98.91% - Test Accuracy: 99.20%\n",
      "[Epoch 45] LR: 0.010 - Train Loss: 0.00033 - Test Loss: 0.00021 - Train Accuracy: 98.90% - Test Accuracy: 99.16%\n",
      "[Epoch 46] LR: 0.010 - Train Loss: 0.00033 - Test Loss: 0.00022 - Train Accuracy: 98.94% - Test Accuracy: 99.22%\n",
      "[Epoch 47] LR: 0.010 - Train Loss: 0.00033 - Test Loss: 0.00022 - Train Accuracy: 98.93% - Test Accuracy: 99.22%\n",
      "[Epoch 48] LR: 0.010 - Train Loss: 0.00033 - Test Loss: 0.00021 - Train Accuracy: 98.97% - Test Accuracy: 99.21%\n",
      "[Epoch 49] LR: 0.010 - Train Loss: 0.00031 - Test Loss: 0.00022 - Train Accuracy: 98.98% - Test Accuracy: 99.17%\n",
      "[Epoch 50] LR: 0.010 - Train Loss: 0.00032 - Test Loss: 0.00021 - Train Accuracy: 98.97% - Test Accuracy: 99.26%\n",
      "[Epoch 51] LR: 0.010 - Train Loss: 0.00032 - Test Loss: 0.00022 - Train Accuracy: 99.00% - Test Accuracy: 99.19%\n",
      "[Epoch 52] LR: 0.001 - Train Loss: 0.00032 - Test Loss: 0.00021 - Train Accuracy: 98.98% - Test Accuracy: 99.23%\n",
      "[Epoch 53] LR: 0.001 - Train Loss: 0.00030 - Test Loss: 0.00022 - Train Accuracy: 99.02% - Test Accuracy: 99.23%\n",
      "[Epoch 54] LR: 0.001 - Train Loss: 0.00031 - Test Loss: 0.00021 - Train Accuracy: 99.02% - Test Accuracy: 99.23%\n",
      "[Epoch 55] LR: 0.001 - Train Loss: 0.00031 - Test Loss: 0.00022 - Train Accuracy: 99.06% - Test Accuracy: 99.22%\n",
      "[Epoch 56] LR: 0.001 - Train Loss: 0.00030 - Test Loss: 0.00022 - Train Accuracy: 99.01% - Test Accuracy: 99.24%\n",
      "[Epoch 57] LR: 0.001 - Train Loss: 0.00030 - Test Loss: 0.00022 - Train Accuracy: 99.03% - Test Accuracy: 99.24%\n",
      "[Epoch 58] LR: 0.001 - Train Loss: 0.00030 - Test Loss: 0.00021 - Train Accuracy: 99.00% - Test Accuracy: 99.23%\n",
      "[Epoch 59] LR: 0.001 - Train Loss: 0.00031 - Test Loss: 0.00021 - Train Accuracy: 99.00% - Test Accuracy: 99.26%\n",
      "[Epoch 60] LR: 0.001 - Train Loss: 0.00032 - Test Loss: 0.00021 - Train Accuracy: 98.95% - Test Accuracy: 99.25%\n",
      "[Epoch 61] LR: 0.001 - Train Loss: 0.00031 - Test Loss: 0.00022 - Train Accuracy: 99.00% - Test Accuracy: 99.22%\n",
      "[Epoch 62] LR: 0.001 - Train Loss: 0.00031 - Test Loss: 0.00022 - Train Accuracy: 99.05% - Test Accuracy: 99.23%\n",
      "[Epoch 63] LR: 0.001 - Train Loss: 0.00029 - Test Loss: 0.00021 - Train Accuracy: 99.06% - Test Accuracy: 99.19%\n",
      "[Epoch 64] LR: 0.001 - Train Loss: 0.00031 - Test Loss: 0.00021 - Train Accuracy: 98.99% - Test Accuracy: 99.24%\n",
      "[Epoch 65] LR: 0.001 - Train Loss: 0.00031 - Test Loss: 0.00022 - Train Accuracy: 99.03% - Test Accuracy: 99.24%\n",
      "[Epoch 66] LR: 0.001 - Train Loss: 0.00031 - Test Loss: 0.00022 - Train Accuracy: 99.01% - Test Accuracy: 99.18%\n",
      "[Epoch 67] LR: 0.001 - Train Loss: 0.00031 - Test Loss: 0.00022 - Train Accuracy: 99.02% - Test Accuracy: 99.21%\n",
      "[Epoch 68] LR: 0.001 - Train Loss: 0.00031 - Test Loss: 0.00021 - Train Accuracy: 99.00% - Test Accuracy: 99.23%\n",
      "[Epoch 69] LR: 0.001 - Train Loss: 0.00031 - Test Loss: 0.00021 - Train Accuracy: 99.04% - Test Accuracy: 99.24%\n",
      "[Epoch 70] LR: 0.001 - Train Loss: 0.00030 - Test Loss: 0.00021 - Train Accuracy: 99.03% - Test Accuracy: 99.25%\n",
      "[Epoch 71] LR: 0.001 - Train Loss: 0.00029 - Test Loss: 0.00021 - Train Accuracy: 99.07% - Test Accuracy: 99.23%\n",
      "[Epoch 72] LR: 0.001 - Train Loss: 0.00030 - Test Loss: 0.00021 - Train Accuracy: 99.06% - Test Accuracy: 99.25%\n",
      "[Epoch 73] LR: 0.001 - Train Loss: 0.00030 - Test Loss: 0.00021 - Train Accuracy: 99.05% - Test Accuracy: 99.22%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 74] LR: 0.001 - Train Loss: 0.00031 - Test Loss: 0.00021 - Train Accuracy: 99.00% - Test Accuracy: 99.22%\n",
      "[Epoch 75] LR: 0.001 - Train Loss: 0.00031 - Test Loss: 0.00021 - Train Accuracy: 99.03% - Test Accuracy: 99.22%\n",
      "Finished Training\n",
      "Best Test accuracy: 99.26\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n---- Start Training ----\")\n",
    "best_accuracy = -1\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # TRAIN THE NETWORK\n",
    "    train_loss, train_correct = 0, 0\n",
    "    net.train()\n",
    "    for inputs, targets in train_loader:\n",
    "        # data is a list of [inputs, labels]\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        ## care! net expect a 784 size vector and our dataset provide 1x28x28 = Reshape!\n",
    "        inputs = inputs.view(inputs.size(0), -1)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _, pred = outputs.max(1)  # get the index of the max log-probability\n",
    "        train_correct += pred.eq(targets).sum().item()\n",
    "\n",
    "        # print statistics\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    train_loss /= len(train_loader.dataset)\n",
    "\n",
    "    # TEST NETWORK\n",
    "    net.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            ## care! net expect a 784 size vector and our dataset provide 1x28x28 = Reshape!\n",
    "            inputs = inputs.view(inputs.size(0), -1)\n",
    "            outputs = net(inputs)\n",
    "            test_loss += criterion(outputs, targets)\n",
    "            _, pred = outputs.max(1)  # get the index of the max log-probability\n",
    "            correct += pred.eq(targets).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        current_lr = param_group['lr']\n",
    "    print(\"[Epoch {}] LR: {:.3f} - Train Loss: {:.5f} - Test Loss: {:.5f} - Train Accuracy: {:.2f}% - Test Accuracy: {:.2f}%\".format(epoch+1, current_lr, train_loss, test_loss, 100. * train_correct / len(train_loader.dataset), test_accuracy))\n",
    "    \n",
    "    if test_accuracy>best_accuracy:\n",
    "        best_accuracy = test_accuracy\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "print(\"Finished Training\")\n",
    "print(\"Best Test accuracy: {:.2f}\".format(best_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
